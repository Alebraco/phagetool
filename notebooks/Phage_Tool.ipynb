{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcRx1XasDSAc",
    "outputId": "f4275bea-0caf-4279-c8e9-8c2c9a8e9d40"
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez,SeqIO\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "E17T_HHIG6Ow"
   },
   "outputs": [],
   "source": [
    "Entrez.email = 'alekey039@hotmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "dGHW8bUyYUSh"
   },
   "outputs": [],
   "source": [
    "def retrieve_ids(query, db, maxrec = 50):\n",
    "  \"\"\"Fetch IDs from an NCBI database.\n",
    "\n",
    "  Args:\n",
    "    maxrec (int, optional): The number of records to retrieve for each batch\n",
    "    db (str): Database from which records are retrieved\n",
    "    query (str): A string used to query the database. The format\n",
    "      should match the specific requirements of the database.\n",
    "\n",
    "  Returns:\n",
    "    list: A list of IDs retrieved\n",
    "  \"\"\"\n",
    "  \n",
    "  ids = [] # Initialize IDs list\n",
    "  start = 0 # Start index for batch retrieval\n",
    "  sleep_time = 1 # Initial sleep time for retrying after an error\n",
    "\n",
    "  while(True):\n",
    "    try:\n",
    "      # Requesting batch of IDs from the database\n",
    "      handle = Entrez.esearch(db = db, retmax = maxrec, retstart = start, term = query)\n",
    "      rec = Entrez.read(handle)\n",
    "      handle.close()\n",
    "      sleep_time = 1 # Reset sleep time after successful request\n",
    "\n",
    "    except Exception as error:\n",
    "      # Retry mechanism in case of error\n",
    "      print('Search failed, trying again in', sleep_time,'seconds:', error)\n",
    "      time.sleep(sleep_time)\n",
    "      sleep_time *= 2\n",
    "      continue\n",
    "\n",
    "    # Break the loop if no more IDs are found\n",
    "    if len(rec['IdList']) == 0:\n",
    "      break\n",
    "\n",
    "    # Update start index for next batch and extend IDs list\n",
    "    start += maxrec\n",
    "    ids += rec['IdList']\n",
    "    \n",
    "  return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Kr6esZxF3bXy"
   },
   "outputs": [],
   "source": [
    "def retrieve_titles(ids, db = 'ipg', maxrec = 50):\n",
    "  \"\"\"Retrieve protein names and accession numbers for given IDs from 'Identical \n",
    "    Protein Groups' NCBI database.\n",
    "\n",
    "  Args:\n",
    "    ids (list): A list of protein IDs for which to retrieve the name\n",
    "    maxrec (int, optional): The number of records to retrieve for each batch\n",
    "    db (str, optional): Database from which records are retrieved. \n",
    "\n",
    "  Returns:\n",
    "    tuple: A tuple containing two lists. The first list contains the protein titles\n",
    "      for each ID in the given list. The second list contains the accession numbers\n",
    "      for each ID.\n",
    "  \"\"\"\n",
    "  \n",
    "  titles = [] # Initialize titles list\n",
    "  start = 0 # Start index for batch retrieval\n",
    "  sleep_time = 1 # Initial sleep time for retrying after an error\n",
    "\n",
    "  while start < len(ids):\n",
    "    idsfrag = ids[start:start + maxrec] # Get a fragment of IDs for a batch\n",
    "    retrieval = False # Indicates successful retrieval\n",
    "\n",
    "    while not retrieval:\n",
    "      try:\n",
    "        # Retrieve batch of summaries from the database\n",
    "        handle = Entrez.esummary(db = db, id = idsfrag, retmax = maxrec)\n",
    "        ipgsum = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        retrieval = True\n",
    "        sleep_time = 1 # Reset sleep time after successful request\n",
    "\n",
    "      except Exception as error:\n",
    "        print('Error retrieving data, trying again in', sleep_time,'seconds:', error)\n",
    "        time.sleep(sleep_time)\n",
    "        sleep_time *= 2\n",
    "\n",
    "    # Extract titles and accession numbers from retrieved data\n",
    "    for entry in ipgsum['DocumentSummarySet']['DocumentSummary']:\n",
    "      titles.append(entry['Title'])\n",
    "\n",
    "    start += maxrec # Update start index for next batch\n",
    "    \n",
    "  return titles\n",
    "\n",
    "\n",
    "def fix_unnamed(titles):\n",
    "  \"\"\"Replace empty strings ('') with a placeholder ('unnamed protein v#'). \n",
    "    Modifies the list in place.\n",
    "\n",
    "  Args:\n",
    "    titles (list): A list of protein titles\n",
    "\n",
    "  Returns:\n",
    "    list: Updated list of protein titles\n",
    "  \"\"\"\n",
    "  \n",
    "  unnamed_count = 1 # Counter for unnamed proteins\n",
    "  for index, title in enumerate(titles):\n",
    "    if title == '':\n",
    "      titles[index] = 'unnamed protein v' + str(unnamed_count)\n",
    "      unnamed_count += 1\n",
    "  return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "-KvCeSVCHF-D"
   },
   "outputs": [],
   "source": [
    "#Download pathogenic bacteria list from Barlett et al.\n",
    "#Store it in a dataframe\n",
    "url = 'https://github.com/padpadpadpad/bartlett_et_al_2022_human_pathogens/raw/master/data/bacteria_human_pathogens.xlsx'\n",
    "bdf = pd.read_excel(url, sheet_name='Tab 6 Full List', usecols=\"F:G\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Na6U1gdW3zoT"
   },
   "outputs": [],
   "source": [
    "#Convert dataframe to list\n",
    "#Join the genus and species column\n",
    "\n",
    "pblist = list(bdf['genus'] + ' ' + bdf['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "hioDhNiS8gTv"
   },
   "outputs": [],
   "source": [
    "# Found random characters\n",
    "# Used .replace to remove them\n",
    "\n",
    "clean_pathogen_list = [species.replace('¬†','') for species in pblist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gTdQliQS7SUl"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mViruses[ORGN] AND phage[All fields] AND srcdb_refseq[PROP] \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mNOT wgs[PROP] NOT cellular organisms[ORGN] NOT AC_000001:AC_999999[PACC]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Execute the function with these parameters\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m phageids \u001b[38;5;241m=\u001b[39m retrieve_ids(\u001b[38;5;28mmax\u001b[39m, db, query)\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mretrieve_ids\u001b[0;34m(max, db, query)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     handle \u001b[38;5;241m=\u001b[39m Entrez\u001b[38;5;241m.\u001b[39mesearch(db \u001b[38;5;241m=\u001b[39m db, retmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m, retstart \u001b[38;5;241m=\u001b[39m start, term \u001b[38;5;241m=\u001b[39m query)\n\u001b[1;32m      9\u001b[0m     rec \u001b[38;5;241m=\u001b[39m Entrez\u001b[38;5;241m.\u001b[39mread(handle)\n\u001b[1;32m     10\u001b[0m     handle\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/Bio/Entrez/__init__.py:230\u001b[0m, in \u001b[0;36mesearch\u001b[0;34m(db, term, **keywds)\u001b[0m\n\u001b[1;32m    228\u001b[0m variables\u001b[38;5;241m.\u001b[39mupdate(keywds)\n\u001b[1;32m    229\u001b[0m request \u001b[38;5;241m=\u001b[39m _build_request(cgi, variables)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _open(request)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/Bio/Entrez/__init__.py:594\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_tries):\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 594\u001b[0m         handle \u001b[38;5;241m=\u001b[39m urlopen(request)\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;66;03m# Reraise if the final try fails\u001b[39;00m\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_tries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1281\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1448\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m   1451\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:942\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m    941\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(\n\u001b[1;32m    943\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address)\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:836\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    835\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 836\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    838\u001b[0m exceptions\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max = 100\n",
    "db = 'nucleotide'\n",
    "query = 'Viruses[ORGN] AND phage[All fields] AND srcdb_refseq[PROP] \\\n",
    "NOT wgs[PROP] NOT cellular organisms[ORGN] NOT AC_000001:AC_999999[PACC]'\n",
    "\n",
    "#Execute the function with these parameters\n",
    "phageids = retrieve_ids(max, db, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tj8U8EAD41s"
   },
   "outputs": [],
   "source": [
    "#Input: IDs of phages\n",
    "#Output: List of bacterial hosts\n",
    "#seq_start and seq_stop parameters retrieve the first feature only (source)\n",
    "#In the source feature, there is information about the host\n",
    "\n",
    "def phageid_to_host(phageids):\n",
    "  phageinfo = []\n",
    "  sleep_time = 1\n",
    "\n",
    "  for id in phageids:\n",
    "    phage_dict = {}\n",
    "    try:\n",
    "      handle = Entrez.efetch(db=\"nucleotide\", id=id, rettype=\"gb\",\n",
    "                            retmode=\"text\", seq_start = 1, seq_stop = 1)\n",
    "      source = SeqIO.read(handle, 'gb')\n",
    "      handle.close()\n",
    "\n",
    "      features = source.features[0]\n",
    "      qual = features.qualifiers\n",
    "\n",
    "      strain = qual.get('host', qual.get('lab_host', None))\n",
    "\n",
    "      if strain != None:\n",
    "        strain = strain[0]\n",
    "        phage_dict['phage'] = qual['organism'][0]\n",
    "        phage_dict['id'] = id\n",
    "        phage_dict['acc'] = source.id\n",
    "        phage_dict['strain'] = strain\n",
    "\n",
    "        split = strain.split(\" \", 2)\n",
    "\n",
    "        if len(split) > 1 and (\"sp.\" in split[1] or \"spp.\" in split[1]):\n",
    "          species = split[0]\n",
    "        elif len(split) > 1:\n",
    "          species = split[0] + \" \" + split[1]\n",
    "        else:\n",
    "          species = split[0]\n",
    "        phage_dict['host'] = species\n",
    "\n",
    "        phageinfo.append(phage_dict)\n",
    "\n",
    "      sleep_time = 1\n",
    "\n",
    "    except Exception as error:\n",
    "      print('Error fetching data, trying again in', sleep_time,'seconds:', error)\n",
    "      time.sleep(sleep_time)\n",
    "      sleep_time *= 2\n",
    "      continue\n",
    "\n",
    "  return phageinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phageinfo = phageid_to_host(phageids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "h5K8Q1ALXA5m"
   },
   "outputs": [],
   "source": [
    "def select_hosts(phinfo, patlist):\n",
    "  pathost = []\n",
    "  patstring = ' '.join(patlist)\n",
    "\n",
    "  for phage in phinfo:\n",
    "    if phage['host'] in patstring:\n",
    "      pathost.append(phage)\n",
    "\n",
    "  return pathost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'phageinfo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pathost \u001b[38;5;241m=\u001b[39m select_hosts(phageinfo, clean_pathogen_list)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'phageinfo' is not defined"
     ]
    }
   ],
   "source": [
    "pathost = select_hosts(phageinfo, clean_pathogen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dictionary of phages with pathogenic hosts\n",
    "\n",
    "with open('phagedicts.json', 'w') as f:\n",
    "    json.dump(pathost, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mCJjng7HSI0l"
   },
   "outputs": [],
   "source": [
    "#List of unique pathogen hosts\n",
    "\n",
    "uniquepat = []\n",
    "for phage in pathost:\n",
    "  if phage['host'] not in uniquepat and phage['host'] != 'bacterium':\n",
    "    uniquepat.append(phage['host'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = 'uniquepat.txt'\n",
    "\n",
    "# Create an empty list to store the lines\n",
    "upat = []\n",
    "\n",
    "# Open the file and read each line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Strip newline characters and add to the list\n",
    "        upat.append(line.strip())\n",
    "\n",
    "# Print the list to verify the contents\n",
    "# print(upat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('phagedicts.json', 'r') as f:\n",
    "    pathost = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "uf-jdHX4hmJl"
   },
   "outputs": [],
   "source": [
    "def receptors(query, recs = 50):\n",
    "    \n",
    "    ids = retrieve_ids(query, db = 'ipg', maxrec = recs)\n",
    "    titles = retrieve_titles(ids, db = 'ipg', maxrec = recs)\n",
    "    titles = fix_unnamed(titles)\n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "  '''\n",
    "  Reads data from a JSON file.\n",
    "\n",
    "  Args:\n",
    "    file (str): The path of the file to be read\n",
    "  Returns:\n",
    "    dict or None: A dictionary with data read from\n",
    "      the file or None if the file cannot be read.\n",
    "  '''\n",
    "  try:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "  # Return None if the file cannot be read or does not exist \n",
    "  except:\n",
    "    return None\n",
    "\n",
    "def store_data(data, file):\n",
    "  '''Saves data to a JSON file.\n",
    "  Existing data in the file will be overwritten.\n",
    "  \n",
    "  Args:\n",
    "    data (dict): The data to be saved.\n",
    "    file (str): The path of the file where\n",
    "      data will be saved.\n",
    "  \n",
    "  '''\n",
    "  try:\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "  except Exception as error:\n",
    "    print('Error writing to file:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pathogens(file):\n",
    "  '''Create a list of unique pathogenic species from a text file.\n",
    "  Each line must contain an individual pathogen name.\n",
    "  \n",
    "  Args:\n",
    "    file (str): File path of the text file with the pathogen names.\n",
    "  Returns:\n",
    "    list: A list of unique pathogenic species.\n",
    "  '''\n",
    "  # Open the file and read each line\n",
    "  with open(file, 'r') as f: \n",
    "    upat = [line.strip() for line in f]\n",
    "  return upat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pathogens(upat, maxrec, output_file):\n",
    "  '''Query information about receptor proteins for each pathogen\n",
    "  and save the data in a dictionary.\n",
    "  \n",
    "  Args:\n",
    "    upat (str): List of pathogenic species to query\n",
    "    maxrec (int): Maximum number of records to retrieve for each batch.\n",
    "    output_file (str): File path where the data will be saved\n",
    "  Returns:\n",
    "    dict: A dictionary of the collected data with 2 keys (titles,\n",
    "     and species).\n",
    "  '''\n",
    "  \n",
    "  # Initialize a data dictionary to store the results\n",
    "  data = {}\n",
    "  \n",
    "  # Read existing data from the output file, if any\n",
    "  # Useful in case of interruption\n",
    "  saved_data = read_data(output_file)\n",
    "  # Initialize a counter to save batches\n",
    "  element_counter = 0\n",
    "\n",
    "  # If data already exists, store it in the dictionary\n",
    "  if saved_data != None:\n",
    "    data = saved_data\n",
    "  # Keep track of already processed pathogens, if any\n",
    "  processed_pathogens = data.keys()\n",
    "  \n",
    "\n",
    "  # Iterate over each pathogen and query for receptor proteins\n",
    "  for pathogen in upat:\n",
    "    \n",
    "    # Skip pathogen if already processed\n",
    "    if pathogen in processed_pathogens:\n",
    "      continue\n",
    "    \n",
    "    query = pathogen + '[ORGN] AND receptor[All fields]'\n",
    "    # Retrieve protein names and sequences for current pathogen\n",
    "    titles = receptors(query, maxrec)\n",
    "    # Store the data in the dictionary\n",
    "    data[pathogen] = titles\n",
    "    # Lists should be of the same length\n",
    "\n",
    "    # Update the counter with the number of elements in each list\n",
    "    element_counter += len(titles)\n",
    "    # If 10 000 elements or more, store the data \n",
    "    if element_counter >= 10000:\n",
    "        store_data(data, output_file)\n",
    "        element_count = 0 # Reset the counter after saving data\n",
    "        \n",
    "  # Return the dictionary with data on receptor proteins\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "upat = read_pathogens('uniquepat.txt')\n",
    "output_file = 'receptor_data.json'\n",
    "data = query_pathogens(upat, 200, output_file)\n",
    "store_data(data, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
