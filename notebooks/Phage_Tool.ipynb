{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcRx1XasDSAc",
    "outputId": "f4275bea-0caf-4279-c8e9-8c2c9a8e9d40"
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez,SeqIO\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E17T_HHIG6Ow"
   },
   "outputs": [],
   "source": [
    "Entrez.email = 'alekey039@hotmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dGHW8bUyYUSh"
   },
   "outputs": [],
   "source": [
    "def retrieve_ids(query, db, maxrec = 50):\n",
    "  \"\"\"Fetch IDs from an NCBI database.\n",
    "\n",
    "  Args:\n",
    "    maxrec (int, optional): The number of records to retrieve for each batch\n",
    "    db (str): Database from which records are retrieved\n",
    "    query (str): A string used to query the database. The format\n",
    "      should match the specific requirements of the database.\n",
    "\n",
    "  Returns:\n",
    "    list: A list of IDs retrieved\n",
    "  \"\"\"\n",
    "  \n",
    "  ids = [] # Initialize IDs list\n",
    "  start = 0 # Start index for batch retrieval\n",
    "  sleep_time = 1 # Initial sleep time for retrying after an error\n",
    "\n",
    "  while(True):\n",
    "    try:\n",
    "      # Requesting batch of IDs from the database\n",
    "      handle = Entrez.esearch(db = db, retmax = maxrec, retstart = start, term = query)\n",
    "      rec = Entrez.read(handle)\n",
    "      handle.close()\n",
    "      sleep_time = 1 # Reset sleep time after successful request\n",
    "\n",
    "    except Exception as error:\n",
    "      # Retry mechanism in case of error\n",
    "      print('Search failed, trying again in', sleep_time,'seconds:', error)\n",
    "      time.sleep(sleep_time)\n",
    "      sleep_time *= 2\n",
    "      continue\n",
    "\n",
    "    # Break the loop if no more IDs are found\n",
    "    if len(rec['IdList']) == 0:\n",
    "      break\n",
    "\n",
    "    # Update start index for next batch and extend IDs list\n",
    "    start += maxrec\n",
    "    ids += rec['IdList']\n",
    "    \n",
    "  return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Kr6esZxF3bXy"
   },
   "outputs": [],
   "source": [
    "def retrieve_titles(ids, db = 'ipg', maxrec = 50):\n",
    "  \"\"\"Retrieve protein names and accession numbers for given IDs from 'Identical \n",
    "    Protein Groups' NCBI database.\n",
    "\n",
    "  Args:\n",
    "    ids (list): A list of protein IDs for which to retrieve the name\n",
    "    maxrec (int, optional): The number of records to retrieve for each batch\n",
    "    db (str, optional): Database from which records are retrieved. \n",
    "\n",
    "  Returns:\n",
    "    tuple: A tuple containing two lists. The first list contains the protein titles\n",
    "      for each ID in the given list. The second list contains the accession numbers\n",
    "      for each ID.\n",
    "  \"\"\"\n",
    "  \n",
    "  titles = [] # Initialize titles list\n",
    "  start = 0 # Start index for batch retrieval\n",
    "  sleep_time = 1 # Initial sleep time for retrying after an error\n",
    "\n",
    "  while start < len(ids):\n",
    "    idsfrag = ids[start:start + maxrec] # Get a fragment of IDs for a batch\n",
    "    retrieval = False # Indicates successful retrieval\n",
    "\n",
    "    while not retrieval:\n",
    "      try:\n",
    "        # Retrieve batch of summaries from the database\n",
    "        handle = Entrez.esummary(db = db, id = idsfrag, retmax = maxrec)\n",
    "        ipgsum = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        retrieval = True\n",
    "        sleep_time = 1 # Reset sleep time after successful request\n",
    "\n",
    "      except Exception as error:\n",
    "        print('Error retrieving data, trying again in', sleep_time,'seconds:', error)\n",
    "        time.sleep(sleep_time)\n",
    "        sleep_time *= 2\n",
    "\n",
    "    # Extract titles and accession numbers from retrieved data\n",
    "    for entry in ipgsum['DocumentSummarySet']['DocumentSummary']:\n",
    "      titles.append(entry['Title'])\n",
    "\n",
    "    start += maxrec # Update start index for next batch\n",
    "    \n",
    "  return titles\n",
    "\n",
    "\n",
    "def fix_unnamed(titles):\n",
    "  \"\"\"Replace empty strings ('') with a placeholder ('unnamed protein v#'). \n",
    "    Modifies the list in place.\n",
    "\n",
    "  Args:\n",
    "    titles (list): A list of protein titles\n",
    "\n",
    "  Returns:\n",
    "    list: Updated list of protein titles\n",
    "  \"\"\"\n",
    "  \n",
    "  unnamed_count = 1 # Counter for unnamed proteins\n",
    "  for index, title in enumerate(titles):\n",
    "    if title == '':\n",
    "      titles[index] = 'unnamed protein v' + str(unnamed_count)\n",
    "      unnamed_count += 1\n",
    "  return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('phagedicts.json', 'r') as f:\n",
    "    pathost = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uf-jdHX4hmJl"
   },
   "outputs": [],
   "source": [
    "def receptors(query, recs = 50):\n",
    "    \n",
    "    ids = retrieve_ids(query, db = 'ipg', maxrec = recs)\n",
    "    titles = retrieve_titles(ids, db = 'ipg', maxrec = recs)\n",
    "    titles = fix_unnamed(titles)\n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "  '''\n",
    "  Reads data from a JSON file.\n",
    "\n",
    "  Args:\n",
    "    file (str): The path of the file to be read\n",
    "  Returns:\n",
    "    dict or None: A dictionary with data read from\n",
    "      the file or None if the file cannot be read.\n",
    "  '''\n",
    "  try:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "  # Return None if the file cannot be read or does not exist \n",
    "  except:\n",
    "    return None\n",
    "\n",
    "def store_data(data, file):\n",
    "  '''Saves data to a JSON file.\n",
    "  Existing data in the file will be overwritten.\n",
    "  \n",
    "  Args:\n",
    "    data (dict): The data to be saved.\n",
    "    file (str): The path of the file where\n",
    "      data will be saved.\n",
    "  \n",
    "  '''\n",
    "  try:\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "  except Exception as error:\n",
    "    print('Error writing to file:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pathogens(file):\n",
    "  '''Create a list of unique pathogenic species from a text file.\n",
    "  Each line must contain an individual pathogen name.\n",
    "  \n",
    "  Args:\n",
    "    file (str): File path of the text file with the pathogen names.\n",
    "  Returns:\n",
    "    list: A list of unique pathogenic species.\n",
    "  '''\n",
    "  # Open the file and read each line\n",
    "  with open(file, 'r') as f: \n",
    "    upat = [line.strip() for line in f]\n",
    "  return upat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pathogens(upat, maxrec, output_file):\n",
    "  '''Query information about receptor proteins for each pathogen\n",
    "  and save the data in a dictionary.\n",
    "  \n",
    "  Args:\n",
    "    upat (str): List of pathogenic species to query\n",
    "    maxrec (int): Maximum number of records to retrieve for each batch.\n",
    "    output_file (str): File path where the data will be saved\n",
    "  Returns:\n",
    "    dict: A dictionary of the collected data with 2 keys (titles,\n",
    "     and species).\n",
    "  '''\n",
    "  \n",
    "  # Initialize a data dictionary to store the results\n",
    "  data = {}\n",
    "  \n",
    "  # Read existing data from the output file, if any\n",
    "  # Useful in case of interruption\n",
    "  saved_data = read_data(output_file)\n",
    "  # Initialize a counter to save batches\n",
    "  element_counter = 0\n",
    "\n",
    "  # If data already exists, store it in the dictionary\n",
    "  if saved_data != None:\n",
    "    data = saved_data\n",
    "  # Keep track of already processed pathogens, if any\n",
    "  processed_pathogens = data.keys()\n",
    "\n",
    "  # Iterate over each pathogen and query for receptor proteins\n",
    "  for pathogen in upat:\n",
    "    \n",
    "    # Skip pathogen if already processed\n",
    "    if pathogen in processed_pathogens:\n",
    "      continue\n",
    "    \n",
    "    query = pathogen + '[ORGN] AND receptor[All fields]'\n",
    "    # Retrieve protein names and sequences for current pathogen\n",
    "    titles = receptors(query, maxrec)\n",
    "    # Store the data in the dictionary\n",
    "    data[pathogen] = titles\n",
    "    # Lists should be of the same length\n",
    "\n",
    "    # Update the counter with the number of elements in each list\n",
    "    element_counter += len(titles)\n",
    "    # If 10 000 elements or more, store the data \n",
    "    if element_counter >= 10000:\n",
    "        store_data(data, output_file)\n",
    "        element_count = 0 # Reset the counter after saving data\n",
    "        \n",
    "  # Return the dictionary with data on receptor proteins\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "upat = read_pathogens('uniquepat.txt')\n",
    "output_file = 'receptor_data.json'\n",
    "data = query_pathogens(upat, 200, output_file)\n",
    "store_data(data, output_file) # Save after previous function is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
